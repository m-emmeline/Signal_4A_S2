{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHARNAY Paul - MONEDIERES Emmeline\n",
    "\n",
    "# Transformée en Ondelettes 2D, application au traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies de base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import scipy as scp\n",
    "import scipy.io as sio\n",
    "import itertools\n",
    "\n",
    "# Affichage\n",
    "import pylab as pyl\n",
    "import matplotlib.pyplot as plt\n",
    "import holoviews as hv\n",
    "import param\n",
    "import panel as pn\n",
    "import hvplot.pandas\n",
    "from bokeh.models import HoverTool\n",
    "from panel.pane import LaTeX\n",
    "hv.extension('bokeh')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation linéaire et non linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Blocks2, Piece, im, im2, Mi = np.load('dataTP.npy', allow_pickle=True)\n",
    "imagesRef = {\"Lenna\": im2, \"Canaletto\": im}\n",
    "imagesRef_coul = {\"Minotaure\": np.clip(Mi, 0, 255).astype('uint8'), \"Cartoon\": plt.imread(\"Cartoon.jpg\"), \"Cartoon_bruit\": plt.imread(\"Cartoon_bruitee.jpeg\")}\n",
    "options = dict(cmap='gray', xaxis=None, yaxis=None, width=400, height=400, toolbar=None)\n",
    "pn.Row(hv.Raster(imagesRef[\"Lenna\"]).opts(**options), hv.Raster(imagesRef[\"Canaletto\"]).opts(**options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 400\n",
    "WT = pywt.wavedecn(im, 'haar', mode='per', level=2)\n",
    "arr, coeff_slices = pywt.coeffs_to_array(WT)\n",
    "hv.Image(arr).opts(cmap='gray', width=size, height=size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approxiamtion non linéaire en seuillant les coefficients d'ondelettes.\n",
    "On pourra utiliser les fonctions suivante : pywt.coeffs_to_array et pywt.array_to_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2D(S, qmf, L, threshold):\n",
    "    WTB = pywt.wavedecn(S, qmf, mode='per', level=L)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(WTB)\n",
    "    WTS = arr * (np.abs(arr) > threshold)\n",
    "    coeffs_from_arr = pywt.array_to_coeffs(WTS, coeff_slices)\n",
    "    Srec = pywt.waverecn(coeffs_from_arr, qmf, mode='per')\n",
    "    ncoeffs = np.shape(WTS[WTS != 0])[0]\n",
    "    return Srec, ncoeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une focntion PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(I, Iref):\n",
    "    mse = np.mean((Iref - I) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    Val_MAX = np.max(Iref)\n",
    "    return 20 * np.log10(Val_MAX / np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise une approximation non linéaire en conservant un nombre N de coefficients d'ondelettes et la tester. On pourra utiliser les fonctions pywt.ravel_coeffs et unravel_coeffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApproxOnd2nonlin(I, qmf, L, N):\n",
    "    WTB = pywt.wavedecn(I, qmf, mode='per', level=L)\n",
    "    arr, coeff_slices = pywt.coeffs_to_array(WTB)\n",
    "    WTS = arr * (np.abs(arr) > np.sort(np.abs(arr), axis=None)[-N])\n",
    "    coeffs_from_arr = pywt.array_to_coeffs(WTS, coeff_slices)\n",
    "    Irec = pywt.waverecn(coeffs_from_arr, qmf, mode='per')\n",
    "    psnr = PSNR(I, Irec)\n",
    "    Irec = np.clip(Irec, 0, 255)\n",
    "    return Irec, psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Irec, psnr = ApproxOnd2nonlin(im,'db2',6,5000)\n",
    "hv.Image(Irec).opts(cmap='gray',width=400,height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un Dashboard qui permet d'explorer la fonction précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approx2D(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\", objects=imagesRef.keys())\n",
    "    wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "    wave = param.ObjectSelector(default=\"haar\", objects=wavelist)\n",
    "    L = param.Integer(7, bounds=(0,7))\n",
    "    N = param.Integer(2000, bounds=(1,10000))\n",
    "    \n",
    "    @param.depends('wave', 'N', 'L')\n",
    "    def view(self):\n",
    "        Im = imagesRef[self.image]\n",
    "        Irec, psnr = ApproxOnd2nonlin(Im, self.wave, self.L, self.N)\n",
    "        strp1 = \"%2.2f\" % psnr\n",
    "        te1 = 'PSNR image bruitée'\n",
    "        TN = pn.Column(LaTeX(te1, size=15, dpi=100), LaTeX(strp1, size=15, dpi=100))\n",
    "        return pn.Row(hv.Image(Irec).opts(cmap='gray', width=400, height=400), TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx2D = Approx2D()\n",
    "pn.Row(approx2D.param, approx2D.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que plus on garde de coefficients plus le PSNR est élevé, c'est logique car on s'éloigne moins de l'image originale.\n",
    "Avec l'ondelette de Haar, on voit apparaître des carrés uniformes. C'est normal car cette ondelette est constante par morceaux, alors qu'une photographie ne l'est pas en général (il y a des nuances de couleur). En revanche si on prenait l'image Cartoon, Haar serait bien adaptée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'experiences qui permet d'explorer la fonction ApproxOnd2nonlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences = {'Image': imagesRef, 'L': np.linspace(2, 7, 6, dtype=int), 'N': np.linspace(800, 10000, 30, dtype=int),'wave': wavelist}\n",
    "dfexp = pd.DataFrame(list(itertools.product(*experiences.values())), columns=experiences.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer la fonction qui à une ligne de la base de donnée précédente calcule le PSNR associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2PSNR(row):\n",
    "    p = ApproxOnd2nonlin(imagesRef[row.Image], row.wave, row.L, row.N)[1]\n",
    "    return {'PSNR':p}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer la fonction sur la base de donnée et ajouter la colonne PSNR à la base de données dfexp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp[['PSNR']] = pd.DataFrame.from_records(dfexp.apply(row2PSNR,axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HoverTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfexp.hvplot('L', 'PSNR', by='wave', kind='scatter', groupby=['Image', 'N']).opts(width=600,tools = [h]).redim.range(PSNR=(0, 50), L=(1, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait judicieux d'éliminer l'ondelette de Haar qui s'avère sous performante, quelles que soient les valeurs de L et de N, pour les deux images étudiées. Cette remarque semble normale car une image n'est pas forcément constante par morceaux.\n",
    "\n",
    "De plus, le PSNR est meilleur avec les décompositions les plus profondes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue un seuillage dur en ondelettes et la tester. On pourra utiliser la fonction pywt.ravel_coeffs et on pensera à cliper le résultat entre 0 et 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeuillageDurOndelettes(I, qmf, L, Seuil):\n",
    "    WTB = pywt.wavedecn(I, qmf, mode='per', level=L)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WTB)\n",
    "    WTS = arr * (np.abs(arr) > Seuil)\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(WTS, coeff_slices, coeff_shapes)\n",
    "    Irec = pywt.waverecn(coeffs_from_arr, qmf, mode='per')\n",
    "    Irec = np.clip(Irec, 0, 255)\n",
    "    psnr = PSNR(Irec, I)\n",
    "    return Irec, psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construire un dashboard qui permet d'explorer la fonction SeuillageDurOndelettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveSeuillage(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Canaletto\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(10,bounds=(1,1000))\n",
    "    @param.depends('wave', 'Seuil', 'L')\n",
    "    def view(self):\n",
    "        Im = imagesRef[self.image]\n",
    "        Irec, psnr = SeuillageDurOndelettes(Im, self.wave, self.L, self.Seuil)\n",
    "        strp1 = \"%2.2f\" % psnr\n",
    "        te1 = 'PSNR image seuillée'\n",
    "        TN = pn.Column(LaTeX(te1,size=15,dpi=100), LaTeX(strp1,size=15,dpi=100))\n",
    "        return pn.Row(hv.Image(Irec).opts(cmap='gray', width=400, height=400), TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveSeuillage = WaveSeuillage()\n",
    "pn.Row(waveSeuillage.param, waveSeuillage.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1, n2 = np.shape(im)\n",
    "B = np.random.randn(n1, n2)\n",
    "sigma = 10\n",
    "ib = im + sigma * B\n",
    "ib = np.clip(ib, 0, 255)\n",
    "hv.Image(ib).opts(cmap='gray', width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire un dashboard qui permet de visualiser rapidement l'effet d'un débruitage en ondelettes et qui renvoie les images originales, bruitées et débruitées ainsi que les PSNR associés aux images bruitéeset débruitées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_bruit(Im, sigma, seed):\n",
    "    n1, n2 = np.shape(Im)\n",
    "    np.random.seed(seed=seed)\n",
    "    B = np.random.randn(n1, n2)\n",
    "    ib = Im + sigma * B\n",
    "    ib = np.clip(ib, 0, 255)\n",
    "    return ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveDebruit(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\",objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"db3\",objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(0,7))\n",
    "    Seuil = param.Number(2.6,bounds=(0, 20))\n",
    "    Sigma = param.Number(10,bounds=(1, 30))\n",
    "    seednoise = param.Integer(1,bounds=(0,50))\n",
    "    @param.depends('wave', 'Seuil', 'L')\n",
    "    def view(self):\n",
    "        Im = imagesRef[self.image]\n",
    "        image_bruit = im_bruit(Im, self.Sigma, self.seednoise)\n",
    "        psnr_bruit = PSNR(image_bruit, Im)\n",
    "        image_debruit = SeuillageDurOndelettes(image_bruit, self.wave, self.L, self.Seuil * self.Sigma)[0]\n",
    "        psnr_deb = PSNR(image_debruit, Im)\n",
    "        strp1 = \"%2.2f\" % psnr_bruit\n",
    "        te1 = 'PSNR image bruitée'\n",
    "        strp2 = \"%2.2f\" % psnr_deb\n",
    "        te2 = 'PSNR image débruitée'\n",
    "        TN = pn.Column(LaTeX(te1,size=15,dpi=100), LaTeX(strp1,size=15,dpi=100), LaTeX(te2,size=15,dpi=100), LaTeX(strp2,size=15,dpi=100))\n",
    "        return pn.Row(pn.Column(hv.Image(Im).opts(cmap='gray', width=400, height=400, title=\"Image originale\"), hv.Image(image_bruit).opts(cmap='gray', width=400, height=400, title=\"Image bruitée\")), pn.Column(hv.Image(image_debruit).opts(cmap='gray', width=400, height=400, title=\"Image débruitée\"), TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wavedebruit = WaveDebruit()\n",
    "pn.Column(wavedebruit.param, wavedebruit.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que le débruitage est efficace, mais que le résultat n'est tout de même pas très net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'images et translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui réalise un débruitage avec une moyenne sur des NbT fois NbT translations et la tester. Vérifier le gain en PNSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DebruitTranslation(IB, wave, seuil, NbT, I):\n",
    "    N1, N2 = np.shape(IB)\n",
    "    Lmax = pywt.dwtn_max_level((N1, N2), pywt.Wavelet(wave))\n",
    "    ISum = np.zeros((N1, N2))\n",
    "    P = []\n",
    "    for j, k in itertools.product(range(NbT), range(NbT)):\n",
    "        IBtemp = np.roll(np.roll(IB, j, axis=0), k, axis=1) \n",
    "        Irectemp = SeuillageDurOndelettes(IBtemp, wave, Lmax, seuil)[0]\n",
    "        Irectemp2 = np.roll(np.roll(Irectemp, -k, axis=1), -j, axis=0)\n",
    "        ISum = ISum + Irectemp2\n",
    "        Irec = ISum / (len(P) + 1)\n",
    "        P.append(PSNR(I, Irec))\n",
    "    return Irec, np.array(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un dasboard pour explorer la fonction précédente. La sortie doit aussi être composée de 3 images et 2 PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Debruit_translat(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Lenna\", objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"db3\", objects=wavelist)\n",
    "    Sigma = param.Number(10, bounds=(1, 30))\n",
    "    seednoise = param.Integer(1, bounds=(0, 50))\n",
    "    L = param.Integer(7,bounds=(1, 7))\n",
    "    Seuil = param.Number(2.6, bounds=(0, 4))\n",
    "    NbT = param.Integer(7, bounds=(1, 15))\n",
    "    @param.depends('wave', 'Seuil', 'L', 'NbT', 'Sigma', 'seednoise')\n",
    "    def view(self):\n",
    "        Im = imagesRef[self.image]\n",
    "        image_bruit = im_bruit(Im, self.Sigma, self.seednoise)\n",
    "        psnr_bruit = PSNR(image_bruit, Im)\n",
    "        image_debruit, P_deb = DebruitTranslation(image_bruit, self.wave, self.Seuil * self.Sigma, self.NbT, Im)\n",
    "        strp1 = \"%2.2f\" % psnr_bruit\n",
    "        te1 = 'PSNR image bruitée'\n",
    "        strp2 = \"%2.2f\" % P_deb[-1]\n",
    "        te2 = 'PSNR image débruitée'\n",
    "        TN = pn.Column(LaTeX(te1,size=15,dpi=100), LaTeX(strp1,size=15,dpi=100), LaTeX(te2,size=15,dpi=100), LaTeX(strp2,size=15,dpi=100), LaTeX(\"NbT\",size=15,dpi=100), LaTeX(str(self.NbT),size=15,dpi=100))\n",
    "        return pn.Row(pn.Column(hv.Image(Im).opts(cmap='gray', width=400, height=400, title=\"Image originale\"), hv.Image(image_bruit).opts(cmap='gray', width=400, height=400, title=\"Image bruitée\")), pn.Column(hv.Image(image_debruit).opts(cmap='gray', width=400, height=400, title=\"Image débruitée\"), TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavedebruit_translat = Debruit_translat()\n",
    "pn.Column(wavedebruit_translat.param, wavedebruit_translat.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec les translations (7 par défaut) et pour les mêmes paramètres que le débruitage sans translation, on observe un gain de PSNR de 3 points, et l'image débruitée est beaucoup plus nette."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan d'expériences pour évaluer l'impact des translations  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un plan d'expériences pour explorer les performances de l'invariance par translation pour le débruitage. \n",
    "\n",
    "On choisit de ne pas tester toutes les ondelettes pour avoir un temps de calcul raisonnable, et car les résultats sont de toute façon très similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar', 'db3', 'db4', 'coif3']\n",
    "experiences_DebruitTrans = {'Image': imagesRef, 'wave': wavelist, \"Seuil\": np.linspace(1, 4, 6)}\n",
    "dfexp_DebruitTrans = pd.DataFrame(list(itertools.product(*experiences_DebruitTrans.values())), columns=experiences_DebruitTrans.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(dfexp_DebruitTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui calcule le PSNR moyen sur n réalisations de bruit du débruitage d'une image avec NbT*NbT translations (qui utilise par exemple la fonction DebruitTranslation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NbT_max = 5\n",
    "sigma = 10\n",
    "def Debruit_Translat_PSNRMoyen(Im, wave, Seuil, n=4):\n",
    "    return np.mean([DebruitTranslation(im_bruit(Im, sigma, seed), wave, Seuil, NbT_max, Im)[1] for seed in range(n)], axis=0)  # Sigma fixé comme un barbare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire la fonction qui à une ligne de la base de données précédente calcule le PSNR moyen sur 4 réalisations du bruit. Puis l'appliquer à la base de données et ajouter la colonne des PSNR calculés à la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DebruitTrans(row):\n",
    "    return {'PSNR': Debruit_Translat_PSNRMoyen(imagesRef[row.Image], row.wave, row.Seuil * sigma, NbT_max)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp_DebruitTrans[['PSNR']] = pd.DataFrame.from_records(dfexp_DebruitTrans.apply(row2DebruitTrans, axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfexp_DebruitTrans.copy()\n",
    "df = pd.concat((df[['Image', 'wave', \"Seuil\"]],pd.DataFrame(df.PSNR.values.tolist(),df.index)),axis=1)\n",
    "df = df.melt(id_vars=['Image', 'wave', \"Seuil\"], var_name='NbT', value_name='PSNR')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser hvplot pour visualiser les résulatst contenus dans la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HoverTool()\n",
    "df.hvplot('NbT', 'PSNR', by='wave', kind='scatter', groupby=['Image', 'Seuil']).opts(width=600,tools = [h]).redim.range(PSNR=(25, 37), NbT=(0, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quel que soit le seuil, on voit bien que les translations permettent d'améliorer le PSNR. Entre 0 et 10 translations, on observe un fort gain de PSNR, après 10 translations, il augmente beaucoup moins vite.\n",
    "\n",
    "De plus, on voit bien qu'en augmentant le seuil jusqu'à un certain point, le PSNR augmente et atteint son maximum. Mais si on continue d'augmenter le seuil, le PSNR diminue à nouveau car on dégrade l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Débruitage d'une image couleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer le débruitage d'une image générale, c'est à dire d'une image couleur dont le format n'est pas carré et dont les dimensions ne sont pas des puissances de 2 on procède comme suit :\n",
    "\n",
    "1) On effectue un débruitage séparé sur chacun des canaux.\n",
    "\n",
    "2) Le format carré n'est pas un vrai problème, il faut juste que les dimensions soient des multiples de puissances de \n",
    "2. C'est la puissance de 2 qui définira l'échalle maximale de la décomposition en ondelettes. Il est donc préférable que les dimensions de l'images soient un petit multiple d'une puissance de 2.\n",
    "\n",
    "3) On étend l'image par symétrie ou périodicité pour qu'elle ait les dimensions souhaitées. A la fin du processus de débruitage on tronque le résultat obtenu à la dimension de l'image originale.\n",
    "\n",
    "4) Si le niveau de bruit n'est pas connu, il faut l'estimer en utilisant les coefficients d'ondelettes de la plus petite échelle (voir le notebook sur le débruitage de signaux).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposer une fonction qui effectue le débruitage d'une image couleur de dimensions quelconques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction peut prendre en entrée un tableau numpy ou une image dans une format d'images classique.\n",
    "Vous pouvez tester votre programme en bruitant vous même une ou plusieurs images de référence et évaluer le gain en terme de PSNR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut améliorer les méthodes par seuillage dans une base d'ondelettes en effectuant un seuillage par blocs. C'est à dire, ne pas décider de conserver ou pas un coefficients en fonction de sa seule amplitude mais plutôt en fonction de l'énergie d'un voisinage de coefficients. \n",
    "\n",
    "Voir : http://www.cnrs.fr/insmi/spip.php?article265\n",
    "\n",
    "En effet, il est rare qu'un coefficient soit significatif seul au milieu de coefficients nuls. \n",
    "\n",
    "La mméthode de sueillage par blocs consiste à choisir une taille de voisinage (par exemple 4*4 coeffients en dimension 2) pour une échelle et une direction donnée et de conserver l'intégralité des coefficients si l'énergie (la somme des carrés des coefficients) est supérieure à un seuil et de les mettre tous à 0 si ce n'est pas le cas. \n",
    "\n",
    "Dans ce cas aussi, les translations permettent d'améliorer le rendu visuel en limitant les effets de blocs.\n",
    "\n",
    "On peut aussi constuire des blocs \"3D\" en considérant des blocs qui comprennent les coefficients des 3 créneaux de couleurs. L'idée est de corréler le débruitage un peu à travers l'espace et l'espace des couleurs.\n",
    "\n",
    "Il est possible d'effectuer un débruitage en changeant d'espace colorimétrique en passant du RGB au YUV par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruiter un minotaure ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de tout ce qui a été fait précédemment, proposer une version débruitée de l'image couleur contenue dans le tableau Mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rédiger également une fonction prenant en entrée un nom de fichier \n",
    "permettant de calculer le PSNR de votre proposition d'image débruitée avec l'image en question.\n",
    "On calcule le PSNR entre deux images couleurs en calculant la somme des erreurs quadratiques sur les 3 canaux.\n",
    "\n",
    "Attention, l'image a 3 canaux de couleur, n'est pas carrée et les dimensions ne sont pas des puissances de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar', 'db2', 'db3', 'db4', 'coif1', 'coif2', 'coif3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EstimEcartTypeBruit(Im, qmf):\n",
    "    N1, N2 = np.shape(Im)[:2]\n",
    "    Lmax = pywt.dwtn_max_level((N1, N2), pywt.Wavelet(qmf))\n",
    "    wsb = pywt.wavedec(Im, qmf, mode='per', level=Lmax)\n",
    "    mt = np.sqrt(2) * scp.special.erfinv(0.5)\n",
    "    return np.median(np.abs(wsb[Lmax])[wsb[Lmax] != 0]) / mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Debruit_couleur(Im, wave, seuil, NbT):\n",
    "    n, m = np.shape(Im)[:2]\n",
    "    new_n = int(2 ** np.ceil(np.log2(n)))\n",
    "    new_m = int(2 ** np.ceil(np.log2(m)))\n",
    "    Im_sym = np.zeros((new_n, new_m, 3))\n",
    "    sigma = EstimEcartTypeBruit(Im, str(wave))\n",
    "    for i in range(3):\n",
    "        Im_sym[:n, :m, i] = Im[:n, :m, i]  # On recopie l'image de base\n",
    "        Im_sym[n:, :m, i] = Im[:-(new_n - n +1):-1, :m, i]  # on symétrise selon les lignes\n",
    "        Im_sym[:, m: , i] = Im_sym[:, :-(new_m - m + 1):-1, i]  # on symétrise selon les colonnes\n",
    "        Im_sym[:, :, i], psnr = DebruitTranslation(Im_sym[:, :, i], wave, sigma * seuil, NbT, Im_sym[:, :, i])\n",
    "        Im_sym[:, :, i] = np.clip(Im_sym[:, :, i], 0, 255)\n",
    "    return Im_sym[:n, :m, :].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_debruit_couleur(param.Parameterized):\n",
    "    image = param.ObjectSelector(default=\"Minotaure\", objects=imagesRef_coul.keys())\n",
    "    wave = param.ObjectSelector(default=\"db3\", objects=wavelist)\n",
    "    L = param.Integer(7,bounds=(1, 7))\n",
    "    Seuil = param.Number(2.5, bounds=(0, 5))\n",
    "    NbT = param.Integer(3, bounds=(1, 8))\n",
    "    @param.depends('wave', 'Seuil', 'L', 'NbT')\n",
    "    def view(self):\n",
    "        Im = imagesRef_coul[self.image]\n",
    "        image_debruit = Debruit_couleur(Im, self.wave, self.Seuil, self.NbT)\n",
    "        haut, larg, _ = np.shape(image_debruit)\n",
    "        echelle = max(haut // 500, larg // 500)\n",
    "        return pn.Row(hv.RGB(Im).opts(xlabel=None,ylabel=None, width=larg // echelle, height=haut // echelle, title=\"Image originale\"),\n",
    "                      hv.RGB(image_debruit).opts(xlabel=None,ylabel=None, width=larg // echelle, height=haut // echelle, title=\"Image débruitée\"), self.Seuil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavedebruit_couleur = Test_debruit_couleur()\n",
    "pn.Column(wavedebruit_couleur.param, wavedebruit_couleur.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, l'ondelette choisie pour le Minotaure est la Daubechies 3, car la photo du Minotaure n'est pas constante par morceaux.\n",
    "\n",
    "Cependant, on peut voir sur la photo du Cartoon que Haar est plus efficace que sur les autres images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantification et Entropie de Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShannonEntropy(x):\n",
    "    value, counts = np.unique(x, return_counts=True)\n",
    "    Proba = counts / len(x)\n",
    "    Ent = - np.sum(np.log2(Proba) * Proba)\n",
    "    return Ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrire une fonction qui effectue la quantification de la transformée en ondelettes avec un pas \"Pas\". On pourra à nouveau utiliser la commande pywt.ravel_coeffs. La fonction doit renvoyer l'image calculée par quantification, le PSNR associé ainsi que le nombre d'octets estimé par la valeur de l'entropie a priori nécessaire pour coder une telle image. On considérera qu'on code séparément les coefficients d'échelle et les coefficients d'ondelettes. Tester la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QuantificationOndelettes(Im, qmf, Pas):\n",
    "    N1, N2 = np.shape(Im)[:2]\n",
    "    Lmax = pywt.dwtn_max_level((N1, N2), pywt.Wavelet(qmf))\n",
    "    WTB = pywt.wavedecn(Im, qmf, mode='per', level=Lmax)\n",
    "    arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WTB)\n",
    "    arr = np.round(Pas * np.round(arr / Pas), 1)\n",
    "    coeffs_from_arr = pywt.unravel_coeffs(arr, coeff_slices, coeff_shapes)\n",
    "    Irec = pywt.waverecn(coeffs_from_arr, qmf, mode='per')\n",
    "    Irec = np.clip(Irec, 0, 255)\n",
    "    psnr = PSNR(Im, Irec)\n",
    "    ent = ShannonEntropy(arr)\n",
    "    return Irec, psnr, ent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer le dashboard asscoié à la focntion précédente. \n",
    "Le dashboard doit renvoyer l'image quantifiée, le PSNR de l'image ainsi que le facteur de compression théorique associé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveQuant(param.Parameterized):\n",
    "    wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "    image = param.ObjectSelector(default=\"Canaletto\", objects=imagesRef.keys())\n",
    "    wave = param.ObjectSelector(default=\"haar\",objects=wavelist)\n",
    "    Pas = param.Number(30, bounds=(10, 300))\n",
    "    options = dict(cmap='gray', xaxis=None, yaxis=None, width=400, height=400, toolbar=None)\n",
    "    @param.depends('image', 'wave', 'Pas')\n",
    "    def view(self):\n",
    "        Im = imagesRef[self.image]\n",
    "        image_quant, p1, ent2 = QuantificationOndelettes(Im, self.wave, self.Pas)\n",
    "        te1 = \"PSNR image quantifiée\"\n",
    "        te2 = \"Entropie image originale\"\n",
    "        te3 = \"Entropie image compressée\"\n",
    "        N1, N2 = np.shape(Im)[:2]\n",
    "        Lmax = pywt.dwtn_max_level((N1, N2), pywt.Wavelet(self.wave))\n",
    "        WTB = pywt.wavedecn(Im, self.wave, mode='per', level=Lmax)\n",
    "        arr, coeff_slices, coeff_shapes = pywt.ravel_coeffs(WTB)\n",
    "        ent1 = ShannonEntropy(arr)\n",
    "        TN = pn.Column(LaTeX(te1,size=15,dpi=100), LaTeX(str(p1), size=15,dpi=100),\n",
    "                       LaTeX(te2,size=15,dpi=100), LaTeX(str(ent1), size=15,dpi=100), \n",
    "                       LaTeX(te3, size=15, dpi=100), LaTeX(str(ent2), size=15, dpi=100))\n",
    "        return pn.Row(hv.Raster(Im).opts(**options, title=\"Image originale\"),\n",
    "                      hv.Raster(image_quant).opts(**options, title=\"Image quantifiée\"), \n",
    "                      TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visu_WaveQuant = WaveQuant()\n",
    "pn.Column(Visu_WaveQuant.param, Visu_WaveQuant.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que plus on augmente le pas de quantification, plus l'entropie et le PSNR diminuent. C'est logique car en augmentant le pas de quantification, on diminue la quantité d'information gardée (donc l'entropie), et on dégrade l'image (donc le PSNR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer dun plan d'expériences pour comparer les différentes ondelettes pour la quantification... et poursuivre jusqu'à obtenir un affichage de la base de données ainsi créée avec hvplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelist = ['haar','db2','db3','db4','coif1','coif2','coif3']\n",
    "experiences_quant = {'image': imagesRef, 'QS': np.linspace(10, 400, 40), 'wave': wavelist}\n",
    "dfexp = pd.DataFrame(list(itertools.product(*experiences_quant.values())), columns=experiences_quant.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2DistorsionRate(row):\n",
    "    Im, p, ent = QuantificationOndelettes(imagesRef[row.image], row.wave, row.QS)\n",
    "    return {'Entropie': ent, 'PSNR': p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexp[['Entropie', 'PSNR']] = pd.DataFrame.from_records(dfexp.apply(row2DistorsionRate,axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h = HoverTool()\n",
    "dfexp.hvplot('Entropie', 'PSNR', by='wave', kind='scatter', groupby=['image', 'QS']).opts(width=600,tools = [h]).redim.range(PSNR=(15, 42), Entropie=(0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HoverTool()\n",
    "dfexp.hvplot('QS', 'PSNR', by='wave', kind='scatter', groupby=['image'], title=\"Evolution du PSNR en fonction de la quantification\").opts(width=600,tools = [h]).redim.range(PSNR=(15, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = HoverTool()\n",
    "dfexp.hvplot('QS', 'Entropie', by='wave', kind='scatter', groupby=['image'], title=\"Evolution de l'entropie en fonction de la quantification\").opts(width=600,tools = [h]).redim.range(Entropie=(0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit bien sur ces graphiques la diminution du PSNR et de l'entropie en fonction du pas de quantification, comme énoncé précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin (à titre informatif et optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons ici d'effectuer la compression sur les 3 canau RGB. Or l'oeil humain est plus sensible à la luminance qu'aux composantes purement chromatiques. C'est pourquoi, la plupart des algorithmes de compressions sont effectué dans un espace colorimétrique YUV où Y est la luminance. On alloue alors plus d'information au canal Y et on comprime plus drastiquement les deux autres canaux. Une méthode standart consiste par exemple à sous-échantionner d'un facteur 2 les deux composantes U et V avant de les comprimer. \n",
    "\n",
    "https://fr.wikipedia.org/wiki/Sous-échantillonnage_de_la_chrominance\n",
    "\n",
    "On obtient alors des images de chrominances moins résolues et donc moins lourdes mais le rendu final reste correct car l'oeil humain est nettement plus sensible à la luminance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
